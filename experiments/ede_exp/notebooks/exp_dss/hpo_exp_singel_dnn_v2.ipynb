{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DNN Experiments Serrano/AUDSOME Phase 1\n",
    "Anomaly Only\n",
    "Gabriel Iuhasz\n",
    "\"\"\"\n",
    "import os\n",
    "# limit GPU allocation\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" #issue #152\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer, classification_report, accuracy_score, jaccard_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "\n",
    "# from sklearn.externals import joblib\n",
    "from joblib import dump, load\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "from subprocess import check_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% utils\n"
    }
   },
   "outputs": [],
   "source": [
    "def custom_scoring_reporting(y_pred,\n",
    "                             y,\n",
    "                             definitions,\n",
    "                             prefix):\n",
    "    \"\"\"\n",
    "    Custom function for handling scoring and reporting\n",
    "    :param y_pred: model predictions\n",
    "    :param y: ground truth\n",
    "    :param definitions: variable class definitions (factorize)\n",
    "    :param prefix: prefix to saved files and images\n",
    "    :return: 0\n",
    "    \"\"\"\n",
    "    print(\"Accuracy score is: {}\".format(accuracy_score(y, y_pred)))\n",
    "    print(\"Ballanced accuracy score is: {}\".format(balanced_accuracy_score(y, y_pred)))\n",
    "    print(\"Jaccard score (micro): {}\".format(jaccard_score(y, y_pred, average='micro')))\n",
    "    print(\"Jaccard score (macro): {}\".format(jaccard_score(y, y_pred, average='macro')))\n",
    "    print(\"Jaccard score (weighted): {}\".format(jaccard_score(y, y_pred, average='weighted')))\n",
    "\n",
    "\n",
    "    print(\"Full classification report\")\n",
    "    print(classification_report(y, y_pred, digits=4, target_names=definitions))\n",
    "    report = classification_report(y, y_pred, digits=4, output_dict=True)\n",
    "    df_classification_report = pd.DataFrame(report).transpose()\n",
    "    classification_rep_name = \"{}_classification_rep_best.csv\".format(prefix)\n",
    "    df_classification_report.to_csv(os.path.join(model_dir,classification_rep_name), index=False)\n",
    "\n",
    "\n",
    "    print(\"Imbalanced Classification report\")\n",
    "    print(classification_report_imbalanced(y, y_pred, digits=4, target_names=definitions))\n",
    "    imb_report = classification_report_imbalanced(y, y_pred, digits=4, target_names=definitions, output_dict=True)\n",
    "    df_imb_classification_report = pd.DataFrame(imb_report).transpose()\n",
    "    classification_imb_rep_name = \"{}_imb_classification_rep_best.csv\".format(prefix)\n",
    "    df_imb_classification_report.to_csv(os.path.join(model_dir,classification_imb_rep_name), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common preprocessing for all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking files in data location ...\n",
      "data\n",
      "df_anomaly.csv\n",
      "df_audsome.csv\n",
      "df_clean_ausdome_single.csv\n",
      "df_clean_single.csv\n",
      "models\n",
      "processed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking files in data location ...\")\n",
    "train_dir = '/Users/Gabriel/Dropbox/Research/ASPIDE/Datasets/ECI Chaos/Distributed Phase 1/finalized/single_node/training'\n",
    "# train_dir = '/home/gabriel/Research/Aspide/workspace/data_phase'\n",
    "# train_dir = '/home/gabriel/research/dipet/serrano/data'\n",
    "print(check_output([\"ls\", train_dir]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting paths and datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting paths and datasets\")\n",
    "# Checking if directory exists for data, modells and processed\n",
    "\n",
    "data_dir = os.path.join(train_dir,'data')\n",
    "model_dir = os.path.join(train_dir,'models')\n",
    "processed_dir = os.path.join(train_dir,'processed')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "# if not os.path.exists(processed_dir):\n",
    "#     os.makedirs(processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_anomaly = pd.read_csv(os.path.join(train_dir,\"df_anomaly.csv\"))\n",
    "df_audsome = pd.read_csv(os.path.join(train_dir,\"df_audsome.csv\"))\n",
    "df_clean = pd.read_csv(os.path.join(train_dir,\"df_clean_single.csv\"))\n",
    "df_clean_audsome = pd.read_csv(os.path.join(train_dir,\"df_clean_ausdome_single.csv\"))\n",
    "\n",
    "# Set index as time\n",
    "df_anomaly.set_index('time', inplace=True)\n",
    "df_audsome.set_index('time', inplace=True)\n",
    "df_clean.set_index('time', inplace=True)\n",
    "df_clean_audsome.set_index('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%% Choose dataset to run experiments on\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset chosen ...\n"
     ]
    },
    {
     "data": {
      "text/plain": "(5400, 90)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dataset chosen ...\")\n",
    "data = df_anomaly\n",
    "\n",
    "# Nice print\n",
    "nice_y = data['target']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment for removing dummy TODO CHECK if adding back dummy\n",
    "# data.loc[data.target == \"dummy\", 'target'] = \"0\"\n",
    "\n",
    "#Creating the dependent variable class\n",
    "factor = pd.factorize(data['target'])\n",
    "data.target = factor[0]\n",
    "definitions = factor[1]\n",
    "# print(data.target.head())\n",
    "# print(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into training and ground truth ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting dataset into training and ground truth ...\")\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ploting class distribution ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gabriel/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEZCAYAAADCJLEQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsyElEQVR4nO3de/ylU93/8dd7hhDJaRyaIW5NylkmER2Q6FcOORTlcJdSyKlSlHRC6u7gEEoHBrckJVKSyOEWaUjJKVPE4GbogO6S4f37Y63N5etrDGbvfX33fj8fj+/ju/e1r2vP+l6z9/W51lqftZZsExER0Tbj+l2AiIiI0SRARUREKyVARUREKyVARUREKyVARUREKyVARUREK3U1QEm6VdK1kq6RNK1uW0zS+ZJurr8Xbex/oKTpkm6StGlj+9r1faZLOkqSulnuiIjov17UoDa0vabtKfX5AcAFticDF9TnSFoZ2B5YBdgMOFbS+HrMccBuwOT6s1kPyh0REX3Ujya+LYGp9fFUYKvG9tNsP2T7FmA6sI6kZYCFbV/uMqr4pMYxERExoObp8vsb+JkkA1+3fTywlO27AGzfJWnJuu9E4IrGsTPqtofr45HbZ2uJJZbw8ssv/9z/goiI6KqrrrrqXtsTRm7vdoBa3/adNQidL+nG2ew7Wr+SZ7P9yW8g7UZpCmS55ZZj2rRpz7S8ERHRY5L+PNr2rjbx2b6z/r4HOBNYB7i7NttRf99Td58BLNs4fBJwZ90+aZTto/17x9ueYnvKhAlPCsYRETGGdC1ASVpQ0gs6j4E3Ar8HzgZ2qbvtApxVH58NbC9pPkkrUJIhrqzNgQ9IWrdm7+3cOCYiIgZUN5v4lgLOrBnh8wCn2v6ppF8Dp0vaFbgN2A7A9nWSTgeuB2YBe9p+pL7X7sCJwALAufUnIiIGmAZ1uY0pU6Y4fVAREe0n6arGUKTHZCaJiIhopQSoiIhopW6nmbfS2vuf1O8i9MRV/7Vzv4sQEfGspQYVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGtlAAVERGt1PUAJWm8pN9IOqc+X0zS+ZJurr8Xbex7oKTpkm6StGlj+9qSrq2vHSVJ3S53RET0Vy9qUPsANzSeHwBcYHsycEF9jqSVge2BVYDNgGMlja/HHAfsBkyuP5v1oNwREdFHXQ1QkiYBbwa+2di8JTC1Pp4KbNXYfprth2zfAkwH1pG0DLCw7cttGzipcUxERAyobtegjgA+Ajza2LaU7bsA6u8l6/aJwO2N/WbUbRPr45HbIyJigHUtQEl6C3CP7avm9JBRtnk220f7N3eTNE3StJkzZ87hPxsREW3UzRrU+sAWkm4FTgM2knQKcHdttqP+vqfuPwNYtnH8JODOun3SKNufxPbxtqfYnjJhwoS5+bdERESPdS1A2T7Q9iTby1OSHy60vSNwNrBL3W0X4Kz6+Gxge0nzSVqBkgxxZW0GfEDSujV7b+fGMRERMaDm6cO/eThwuqRdgduA7QBsXyfpdOB6YBawp+1H6jG7AycCCwDn1p+IiBhgPQlQti8CLqqP7wM2for9DgUOHWX7NGDV7pUwIiLaJjNJREREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREK3UtQEmaX9KVkn4r6TpJn67bF5N0vqSb6+9FG8ccKGm6pJskbdrYvraka+trR0lSt8odERHt0M0a1EPARrbXANYENpO0LnAAcIHtycAF9TmSVga2B1YBNgOOlTS+vtdxwG7A5PqzWRfLHRERLdC1AOXiwfp03vpjYEtgat0+FdiqPt4SOM32Q7ZvAaYD60haBljY9uW2DZzUOCYiIgZUV/ugJI2XdA1wD3C+7V8BS9m+C6D+XrLuPhG4vXH4jLptYn08cntERAywrgYo24/YXhOYRKkNrTqb3UfrV/Jstj/5DaTdJE2TNG3mzJnPuLwREdEePcnis/034CJK39HdtdmO+vueutsMYNnGYZOAO+v2SaNsH+3fOd72FNtTJkyYMDf/hIiI6LFuZvFNkLRIfbwA8AbgRuBsYJe62y7AWfXx2cD2kuaTtAIlGeLK2gz4gKR1a/bezo1jIiJiQM3TxfdeBphaM/HGAafbPkfS5cDpknYFbgO2A7B9naTTgeuBWcCeth+p77U7cCKwAHBu/YmIiAE2RwFK0gW2N366bU22fwesNcr2+4BRj7N9KHDoKNunAbPrv4qIiAEz2wAlaX7g+cASdUBtJ2FhYeBFXS5bREQMsaerQb0P2JcSjK7i8QB1P3BM94oVERHDbrYByvaRwJGS9rJ9dI/KFBERMWd9ULaPlvRqYPnmMbZP6lK5IiJiyM1pksTJwIrANUAns64z7VBERMRcN6dp5lOAletceBEREV03pwN1fw8s3c2CRERENM1pDWoJ4HpJV1KW0QDA9hZdKVVERAy9OQ1Qn+pmISIiIkaa0yy+i7tdkIiIiKY5zeJ7gMeXuHgeZfHBf9heuFsFi4iI4TanNagXNJ9L2gpYpxsFioiIgGe53IbtHwIbzd2iREREPG5Om/i2bjwdRxkXlTFRERHRNXOaxbd54/Es4FZgy7lemoiIiGpO+6De1e2CRERENM1RH5SkSZLOlHSPpLslfV/SpG4XLiIihtecJkmcAJxNWRdqIvCjui0iIqIr5jRATbB9gu1Z9edEYEIXyxUREUNuTgPUvZJ2lDS+/uwI3NfNgkVExHCb0wD1buBtwP8CdwHbAkmciIiIrpnTNPPPArvY/iuApMWAL1ICV0RExFw3pzWo1TvBCcD2X4C1ulOkiIiIOQ9Q4yQt2nlSa1BzWvuKiIh4xuY0yHwJ+KWkMyhTHL0NOLRrpYqIiKE3RzUo2ycB2wB3AzOBrW2fPLtjJC0r6ReSbpB0naR96vbFJJ0v6eb6u1kzO1DSdEk3Sdq0sX1tSdfW146SpGfzx0ZExNgxx7OZ277e9ldtH237+jk4ZBbwIdsvB9YF9pS0MnAAcIHtycAF9Tn1te2BVYDNgGMlja/vdRywGzC5/mw2p+WOiIix6VkttzEnbN9l++r6+AHgBsosFFsCU+tuU4Gt6uMtgdNsP2T7FmA6sI6kZYCFbV9u28BJjWMiImJAdS1ANUlanpL19ytgKdt3QQliwJJ1t4nA7Y3DZtRtE+vjkdtH+3d2kzRN0rSZM2fO1b8hIiJ6q+sBStJCwPeBfW3fP7tdR9nm2Wx/8kb7eNtTbE+ZMCEzMUVEjGVdDVCS5qUEp/+2/YO6+e7abEf9fU/dPgNYtnH4JODOun3SKNsjImKAdS1A1Uy7bwE32P5y46WzgV3q412Asxrbt5c0n6QVKMkQV9ZmwAckrVvfc+fGMRERMaC6Odh2fWAn4FpJ19RtHwMOB06XtCtwG7AdgO3rJJ0OXE/JANzT9iP1uN2BE4EFgHPrT0REDLCuBSjb/8Po/UcAGz/FMYcyygBg29OAVede6SIiou16ksUXERHxTCVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREKyVARUREK3UtQEn6tqR7JP2+sW0xSedLurn+XrTx2oGSpku6SdKmje1rS7q2vnaUJHWrzBER0R7drEGdCGw2YtsBwAW2JwMX1OdIWhnYHlilHnOspPH1mOOA3YDJ9Wfke0ZExADqWoCyfQnwlxGbtwSm1sdTga0a20+z/ZDtW4DpwDqSlgEWtn25bQMnNY6JiIgB1us+qKVs3wVQfy9Zt08Ebm/sN6Num1gfj9weEREDri1JEqP1K3k220d/E2k3SdMkTZs5c+ZcK1xERPRerwPU3bXZjvr7nrp9BrBsY79JwJ11+6RRto/K9vG2p9ieMmHChLla8IiI6K1eB6izgV3q412Asxrbt5c0n6QVKMkQV9ZmwAckrVuz93ZuHBMREQNsnm69saTvAK8HlpA0A/gkcDhwuqRdgduA7QBsXyfpdOB6YBawp+1H6lvtTskIXAA4t/5ERMSA61qAsr3DU7y08VPsfyhw6CjbpwGrzsWiRUTEGNCWJImIiIgnSICKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhWSoCKiIhW6tqS7xERMXtf/dCP+l2EnvjAlzZ/VselBhUREa2UABUREa2UABUREa2UABUREa2UABUREa2UABUREa00ZtLMJW0GHAmMB75p+/A+FymG3PpHr9/vIvTEZXtd1u8ixJAaEwFK0njgGGATYAbwa0ln276+vyUbXLd9ZrV+F6Enljv42n4XISKewpgIUMA6wHTbfwKQdBqwJZAAFdFSF7/2df0uQs+87pKL+12EgTRW+qAmArc3ns+o2yIiYkDJdr/L8LQkbQdsavs99flOwDq29xqx327AbvXpSsBNPS3o7C0B3NvvQrRcztHTyzmavZyfp9fGc/Ri2xNGbhwrTXwzgGUbzycBd47cyfbxwPG9KtQzIWma7Sn9Lkeb5Rw9vZyj2cv5eXpj6RyNlSa+XwOTJa0g6XnA9sDZfS5TRER00ZioQdmeJekDwHmUNPNv276uz8WKiIguGhMBCsD2T4Cf9Lscz0Ermx5bJufo6eUczV7Oz9MbM+doTCRJRETE8BkrfVARETFkEqAiYkySpH6XIborAWoukfQuSdtImr/fZYkYZJImATj9E08wiAE7Aeo5krSApKuANwB7AIdL2rHPxWqdQfzydIOkd0t6b7/L0VaStgSOlLRcv8vSJpLGdQK2pD0lPWnQ61iUAPXcLQfcaPudwFaUMVuvkbR1X0vVIiO+PMv3uTitJekdwJuA8/tdljaS9P8o37FP2L4tNz2Ps/0ogKS9gA2Av/W1QHNJAtRz9zAlIK1q+wHgZ8CvgA0lvbS/RWuHxpfnzcD3BuXu7rlqXmAlvQp4N/AP27eOfH0YSRrXeDwv8BZgLeDFkCa+kSS9D/gC8DnbD9dJDca0BKjnqM6wfgzwfkkL254J/BKYH1gccqGBx748+wM713M01Dq1ytpEPC+l5n0ysLSkTWC4L8D1/DwqaTFJG1Emh94LuBxYLU18j5P0gvpwKnAR8CkA2/8e69eeBKi54wfAv4APAdi+kTIZ44b1+dBdaOoaXk13UJoeXlZfHzODxLuhXnxfQ2nO+xawT338Y2AbSavD8N7c1POzNmX2mFcBPwS2Bb4CrAq8UdKS/SthO0h6F/ANSQdTzsuuwAslHQRj/9qTADUX2L4ZOB2YJOlkSS+jLK54W39L1h+SZPsRSS+StKukNSkXmvcCn5K0XJ2+amQQGxq1Se8w4F2Uu96PAwbOpXxuPihpqbF+gXkmOk16KuYB9gP2BM4EngfMa/sPlJrmW4F1hi2Aj2gW3hnYhXJjvAXwPuA+ys3OVnV1hzEtAWousX0l5YPxEKUp64e2T+lvqfqjNl2tC/wCWJrSBLofcBrlTvibkuax/Uj/StlbkhZvPF4A+CfwTeCVwPuB7W3fZXs6cBalKesv/ShrP0hagtq3BKxJCUgPAGsDJwEft32KpJfbPh/4MnDhkAXwF9TvVue6vQhwCLAR5brzWdsPATcCnwWW6UtB56JMdTSX1Tuc8bZn9bss/VK/QF+i3OnOAK4E9rD9k3pxPgW4zfZ+fSxmz0halHKHuxCwMnAZJUAdSMm2er/tP9Wgvo3t/RvHahguwjXr9dXAZGCc7c0lfZUSvJexPVPS8yk3OUfYvrAeN66ThDPIasLVfpQmzn2AE4DVgY8CN9jequ63JfBA5/yMdalBzWUuhio4SVpD0pvq422AFwB3AR+jTPD7rhqcXgw8n9Is8dF+lbcP7qd81w4DXm77VNtnAtOBPwALSHo1paZ5R/PAQQ9OjdrAzyljCV/C45+NvSnB/As1yeZC4OrmxXcYghNAbdpcFLgauNX2NOCPwO+AMwAkbQt8vnncWG8CTYCKueEO4BBJV1DG8TwK/JXSvHeA7V9IWhb4HvBq2w/WDKNh6YOaH7iEkgRxnaTX1u3vB2YB+wKfAQ6zfUQ/CtgPtXb4qKTJwPrAByjn6Q2SVqrB542UlbEXB75g+1P12IG/do3ob1oQuB24ipLRiO2LKU3mr5d0HvBBSlNxM4CP6RucNPHFs9ZsXpF0LvAKYHPbV0paiXIBXha4FdgU+NYwXYABJL0NOIhSOzBlsc1Vga/YvlHSyravl7SI7b/VY4aiWQ8eu+v/OGXszumSXkkJ2BcA36H00V1j+/7GMQN/fpp/o6TPULKEvwr8G/gpcFEjWC9WD/un7X8OUrNnAlQ8YyO+PJ2lox8BVqG0j29v+481MWAy8FJKn9NF9ZiB+QLNjqSdKHe177F9Vd02iTIgdzlgCeAa4DO1JjHwF94mSS+nrE30dtt3SloIEOXzshflHC0MbFgHwQ8dSccBLwLeZ/t/67a1KP24XwPWA75Xm4wH7ruVABXPmqQdKFlEH7L9w7rtUEoz3oY1DfY3tq9tHDOwF+ERgXs8cAAlAN0JrEGpPR0C3E0ZhvAy23v3p7S9N/LiqTLt1Q8pyTSLA6sB6wBTKE2fq9s+r/clbQeViaePAI6j1JxeA7yQcs5eSBmQe6ntz4/+DmNfAlQ8K5JeRBn7taft39aR/fMAMykpwOsDf6LcHf+jfyXtDT0+88EClCzOByVtBXyC0nfwMx6vTW5d04E7x44f9JT7xvmZn9JPea3t6ZK2B7amBKlLKUM0brZ9YuPYgT8/TZIWtP0PlRlGvkRpOr+VMsZpGeB/bB9V084fqMcMVM2pIwEq5sjIi4SkpYGDKYk2syhzpD0IHGf7h5Jea/uSuu/A1pqaVGZ/OBq4lpI4cgQlQeJBl7nRXkWpQe1s+656zFCcGwBJKwLfpyRCrEVpojqt87mStDGln+U9ti/rW0H7qKaJ70sZB3ex7fM6/ZT19UOARWx/oBH0B/YzNPCZMPHc1S/CI5IWkbR3vZDMpKS33kEZSLkpcAUlKYJGcBo/qF+eJpXZMr5Nadb7HbAj8DmAGpw+T7kgH9wJTvW1YTg3Upkg+HDK+fko8B+UJs9tJS1cL8zHUsaEDWtwejclYWRfyrX565I2qUk0k2p/1PqUjM/HUuwH+TOUABVPq96lrUmZhmcRYGdKTelC2591mUXjdZTBqDeOOHYgm2ZGSXOejzIP2iOUdOnjKf0E76uv3w5sZvvyYUuRrmMDZ1IC03RK7WBvyrim/SmfnUuA9W1fPNbH7swpPXG29udRmvA2o8yksT4lYB9Vxw/OD9xhe0Pb9wzLEI008cWoRnT4L0iZOuVHlBrTqcC8wK9s76YyOHdPypinK/tV5l4ZcW5eD1xh+1/1+XHAd2xfIum/KTWFAxsZjMPWn7IvJb3+RNt/l/QWSr/kTvXC+yPK+KZT6v4D2ZcyUuczVAPTC4G/u4wNfCklKWIX2zMkdRKM1mgM6Riaz9BQzygdoxv5BagdtodTUn6/R7nrvQW4tF6AjgTOq4kBA32BaVxY5gG+C6wEXCzpV7ZPooxxWk3SDZRZMz7ZCU4wuDXKDj1xbNxXgOUp15nJNXjfCKwn6aOUOeS+6caclYP82Wmqn6HlKOO9rgYeUVlJ+f8ozecPq8zOciZwefO8DPpnqGngmxrimWt0Wh8paX9JW9i+h9K8d6ntnwPjKU00K9YmnAfrxXtgLzCN4LQQZSmVX9peldL3toGk9Sjjd3ahzBpxnu2f1WMH/rvW+f+v/SWvoCSHvBXYhjK7yHaUcU7voiy78j3bR9VjB/78NKkMrl2dkjSzK/B3ykD2GZQgdQSlmfhHts/tVzn7LTWoeMyIu9/3AytSxvF8QtKjwPXAWpIOAHYAPm37B53jB7mzFh67630jpZP6EWBafelnlD6CXSkXlvWAxWtQZ9ADd0c9P6tTkmd+D2wh6Ze2z5V0LKXmvS3lHP2ycSM00LVueFKz8O6U8zAe+GK9ufsIcKqkg22/W9JE4N8uk+QObJbe0xmqu5YYXadTut79Tpb0IWApSjv4CZTsq8MoU/p3lhT5r05wGpa735q9uDtlCqejgLdIepntuyk1pjuArQBGBKehuLiozDH4AUpf5NaUfslDJK3osojn6ZQBuU9YamXQgxM8fvOmMuntK4BPU2ayX13S8i7jmfYCdpa0ue07anAaNyyfn9GkBhXNL89alHEof6aM5v+DpB/a/n7t0L4AWNf21Z1jh6V2UP/+7YHlbV8DXFM7tE+U9Cbbt0r6FnB784IyZBeXVSh9cNdLmtf21yUtA3xb0htdxvScPwyfl9HU79dRlJlXLpH0f5SgtJmkM+tnaGPbf+4cM6znqmMo7nzj6aksP/5d4CDb76AspvdqSqDC9pcpS5M/4TMzLBfgetE4CbhJ0n5122cpSx6cXZ/fVpu5hvJ7Zfs4yjQ8K1BSpaE0h94LvLPu8+iwpJGPZPs3lJrT3pIWd1ky4zuUGds3qUH9z/DYVFlDL2nmAUC9070E+IVL6vh4Smr5/JS06V839h34PoOmRnLEvMDmlEHJlzZSo99i+5y+FrLP9MSpjD5HmVXku7Z/L2k+N6Z2GnaSvgisYruzhtpOwFWus0XE44byTi+ezGV2g7cCUyTtUvsIvgJMoKSXN/cdmuAEj9cSbT9Maeb8JaX/aZO6feiCU+cOv1NbrMFpnMt4sC9S5hzcVNL8neA0rDXLURwM/FXSDwBsn5zgNLrUoIbMiGyiJ9WEJG1KuQPe3/YFaqxTNMhGnJfn2f53ffykQZEqS2ZsBPzE9r29L21/SVqD0mR3oMsUWM3sz05tczXgPtt39rWwfaKyztWfmy0PI16fSJlN42PAo8PSVP5MJUANCZUVbRe1/TtJqwI3jLzwNvbdmzJm5Q3ArHoRGthstBHB6UuUGuPdtg+q20YL5J0L8cCelw6NmJRU0oaUuQavt/2lus9sb3wG3Yi/fzFK8/ipti8b7SbnqY6NJ0qVe3jMA5ylMiPEVylNMKNyGTy5ue2HOl+sQf0CNdN4VQbavpQyQHIzSUfDEzv2O01b9UK99KCel6ZGsHlD/X05ZUaRVST9Z93nScFJ0islrdzj4vZF/TzMVx//hTKv3ofq85E18PEjj+1VOceaBKgBp2Kc7VsoF5YPUsap3FA7/Ufu3+lT+Fvn+F6Wt5c6KfKSlq7B6C3AN2qzzCaUmbZ3b+z+2J2wysDKoyXNP6jnqPl3qax+e15NF/8XcCVlJpHNa40KSfM0gtN+lHXB/t37kveeyurRn5F0VN30ReBulUmWm/s1P0NTVdbDiqeQADXA9PhSF507tG9Sak9fh8c6/Ufu37nAbC5p4iDf3dW73uUpA5HnAdYG3iBpsu2/UgLWMXVsyqONC8tXKVMd7WH7X4N6jjq1xJoSfQMlieY7klaotYSrgSWBd9e+ylkAko6gzMq9ve3p/Sp/N40I3osAfwVOBCapzEG4D2UuxgXqPuP0+LI1CzcSJE7rddnHkgSoAVVrB4/UDv2vSfocpc/xg8ANkn5S93tFvTtuzsH3UUrzxMAmAEgaL2kl4Drg97Z3pwSqfwH/T9IStq+irPY6ox6zoKSfA/PZfpPLEhIDS2WNph8D3601xvMp45oulLQkpZb5G+Cjtv9Wz+lxwNKUpUXu6FfZu2lEf9NBlAldv0Dpu9yWsijjYsA7gI+ppNk/WmvrawA/Ba62vUt//oKxI0kSA0Z1uej6eFngPMr0/YtTpi/6o+0vqkzjfwulz2UX27+qxxxDuUjvP2gd3U+R7HAC8BrbL6nPt6asT/RHyppXD9ft8wAbAKvZPrq3Je89SW8H3kaZP+8llPkFF7W9r6QvUxamXAp4q+376jELARvY/mmfit1Tkj5Gma/yK5TAtAzwM9vfr6/vBLwWOMSPD8D9NDDD9jf6U+qxJQFqgEjaiDJT9IEua8msB+xte4f6+gbAfwKfAP5BWWDwMtu31Avwd4CLbB/Tlz+gi0bc9X6GMnv0FTXL6mLKFEU71tf3AmaObH6pfSyzel32XhiR3LA0pSl4Jdur1W2vAPYDPu8y+HbR2gza6bf0oDZ1jkZl0uBTKdMWTa01yjdTll85zPb9db9zKetd/aI+H7oMx+ciTXwDxPaFlDbvnevd7F3AyiqTeAJcRrnLW9X2/bZPqcFpfL3w7j6IwQke6095vqQLKJ/75wFfVhmvswmwjqRD6u7HjdY3MOjBSdILJH0YeJgyFu7vkvYBcJl/cUFq9mczONXmq6EITp1MPeAi4NvAbpImuEwO/FvKFE+dgcmLUyaGfew6m+D0zCRADQA9cYT+dZRaUqcP6RvAOyStVi8iC1DW5HlMI5V8YPucqlUoNcSDgNcAF9u+1mVQ7puBPVQGUHZqWgOZnTdSDU6TgXOBpWuT3e8o/U1bSzqg1sZXotz0POHYnhe4TyTtAJwk6fvAGpS5KS8ATqjB6FWUa+r8APU8bmL7gj4VecxLgBrDJC1QH1rSQpI6bf/HUILUxpSO7T8BUyVdTplr72c9L2yPjciy6tz1PkBJi76JMgvER+rrb7V9M/Bil2UOBnrs11PYlrLA4ofhsQzPS4GTKcuL7ANsZfvy/hWxf1RWt/0wcCgleL8fWJnSzLc4ZU2wlYDtXJa27wzX+F1/SjwYstzGGFX7Cc6S9G7b10lakbLOzifr6zOAg4AP2/6CpJOBeW3fVl8f6LbwRn/T3sBKks6grHz7K2C87a/W108G5pF0DmWC02H1YkrtG0kvcFmfaBYlI20cZcbtu+vrAz/zwSjfj4nAr2vA+Z2kPShp9G+vn7HdgD/U4DTbmSNizqUGNQbVL8//UpY2+Grtb/pf4F5Jq9W01u9TsvS+Lmkl23c1gtPAruHUbO6UtCOwJXADpVa5LqUZ6x+Srpb0M+AR2zvYfnjQL7pP40fAByUtZ/sBlVnJjwcWBc6hNO19AAa/ZjmiT+5ASQvz+FCDlwHYPhZ4scqaYNcAPwB2kLRmgtPckxrUGDMiuEyjLP9whO33SLqPMpjyh5RmiJsod71/br7HoF5gOuemBux3AAtRBtPeJOlhShbap4ADKf1R8zfS64f2rreetx/XhJHzJR1PafL7pe0/1X0+WxMBBl6jT+4E4HLb99dmYQFb1azPeevzB20/LOkS4E+2b+pfyQdP0szHKElTgfmA6ynp4ucAn6cMGFyG0mRzhe296v4D3ywDIGkpSnbVLGAScKPtd9bXPg2sA3zA9h8bxwx0c2etVb7E9h9UZj14tJMGPcq+2wDj6z5njPL6sHyODqQ0mX+2se2VlPkIN6AkG33a9sV9KuJQSIAagyS9EDjB9tb1+bLAGcCXbX9X0osoY1iGauyFyij9A4FrbB9en+9H6Rs4rO5zBHCky9yEQ6HWBnauT3cAdvCIZSCe6jMyLJ+dkSR9DbjO9tGdPrlOcJa0KPCw7QeH9fz0SvqgxqaFgTVqkwzAHZR012MkbW77zmELTtW9lNrjijXD8TpKbeqVtVMb2/sOS3DqZDLWDMUFKbNCfGNkcKr7PKpi3MjtPSls+4zWJ3eCpJfa/muCU28kQI1Btm+nTPj6LUkL1S/JvXXbH0fsOxRfoHqxuIMy/msysKnLwNorKEtDLNLZr2+F7CE1lhGpplJSpJeQtJ7KzCFP2r8GqtUlvaWZqj9MOn1ylO/T+ZI+BPwCuNf2Hzr7Dct3q5/SxNdSNRPvoVG2N6fs+Tqls/9eSkLAVvXObij6CUZqNMG8DXg3cKjtS9VYIXcYNM7DOOAUShbjfLYPkvQF4BHgSMqA5CUoCw92PlNvpySSvM/2JX35A7rsufbJDev3qx8SoFqo9p08avtaSVsAP32qC6ykKcASrhN0DvKX5xleWA6iTHD6Dtt/r9sG9tyMVFOjv09Zs+lsyqzjbwRupgSghyn9Ue9tXHgPAjalJJH8tg/F7on0yY0dCVAtJGkTyhfoP4A7bW83yj6jzcw9sJOZwhxfWJo1zBWb2XrDRGXqnR0pTXvfBa60/Yn62mLUOeNsX1a3fZwyVc8urvPsDZoRn40vA3sAn7T9+afan3KNTEDqkwSolmh0aFtlSegLKYMkd7B93VMc01ydc2Dv7J7FhWUozkvHiPOzOqXp7u/AxZR0+4/YPrO+vj9wiu27msdKeoXLhLADaeTnoLZSbEFJOPoBZZaIWaPtX8/pcsCPh6UG3hZD0WHcdo0OateU8fkpNYUzgHdqxLLR9ZjxLgsSStLBlDV7Bs6z7OzvBKfVKYsPDmxn/4jg9C7KOLgdKTMffAF4nu0zVWZF+A5lktMnTQo84MGpM4B7nKRTJX2CMmfeZynBfAvK52kpSat09q/Hvp1SA70/wan3EqBaoPFl2IOScfY5ymSvX6Asqb2RpGUl7VV/d1bLnUiZDPbmZnbRoMiF5ek1gtOJwEaUZdinAHtRUuzPUplE+Gzgbts7usx8oObxg6ze+C1MWbzzWkqN6SOSXk9JFlkCOBi4EXh545weRJneaftBTRhpuzTxtYSkdwLbU2pO+wHb2l5Z0tqUjLRVKSvdbla/cOtRvlzvHfAO7XT2j6LRNDcf8CLgm7Y3rq+9lbJ8yHm2vydpQWBi5yZGQzitU/rkxqYEqD4ZpU18O2AmZZ2i1wHvtH23Hl8q4iWdvihJy1NqWfvavru3Je+tXFiemqSVgS9SaktfB461/YP62qnACynzNJ7fOCZ9cumTGzPSxNcHjaarRSTtVi/C4yizQSxr+w01OG0LfJDSSnFd49hbgR0HLTg1+4pUBouuRpkBYV/g18DXGsFpf8rYngtdlm3vHHuu7S2GIDhtDHwM+HrNVPwRsIqkDeouN1HWv1q/edyQBaf0yY1xCVB9UO/QNqAsAfEhStPeGcBxwCRJE1XWmDkEuNSjjIEatCaaXFhmb5REj8mUGds7K9xeAvwTOFLSeZSkmS8Dq0l6fs8K2mfpkxssaeLrET0xbfU1lLV23gNsBiwL/Bz4DiVIzarb9rX9x+bFe9DVC8t44HZKU93ZwNeA/wJeSpnB/be29637D/y5GfHZWQL4a02SOQZY1fbr6mvzUQLXYsAvgWOBWbb36FPReyZ9coMpAaoHRlxglgTeBLzW9q5123so6zr9l+3/qds6aeQD3WeQC8vsNT4Hi1CC9U2UpVQ2pySInEiZUeM/G8csRAnq99j+YK/L3C/pkxs8aeLrgUZwOgL4MGVutEVrhh6UhdGWBt6qx1fsfKSZNj2oanBaGTiT8nm0pK3ra2cCzwf+U9Imtv/RCE7jBjk4qY7vqp+DyZRMxhMo/XGvpySNjKdkfL5M0iGdY20/CBzWCU4aggly0yc3mAb+g9sGkuaTdDowr+2PANMpS0G8VdKqlCmN7qakkq/SOW7Qm64gF5bR1P6QbVWWG98A2B34CnARpSl4X2AicJzt+4CdKJPCNmckub7zfBDPVfrkhkOa+LpgtGYDlZnHt6Rk6T2ssjrnxpSmmgWArSnLbD9k++hel7lXRvYZSXo/pa9kXdtXSlqLcl52oCRB3AMcDXwU2Mn2//Wh2D0n6QWU1ZLnA15l+xaVgcoL2j5AZVjCd4EtbJ9TjxmK5qr0yQ2PBKi5bMSXZx1KwPltfX4G8E/bOzX2n0ipIWxMyVbb1oM7uDQXljmksuDiiZQa9T62L5C0J7AWJfvzPcCfbH+pf6XsvfTJDZcEqC6R9ElKB//NwPy2t1EZ73QKcLXtjzf2XY9SQ9jb9m19KXCX5cLy7Eh6A6Vp6h2Uz9LRwCuBM21/pu4zDMkij83UX/vkvkb5Lp0O/JUyfdFOlMlffwz83PZBjeNXbjR7DkVNcxAkQM0FtT189UZN6VOUmR92VJnZ4GBKRtF+NSHgHEpz1WXN9xjEPqdcWJ47SftS5mb8PLANcJTr3HCD+rlpqt+vtwMrAJdSmsMvpPTjngqcTGkSvsn2e+rnbLztG0dpUh748zVIEqDmgpr+fBhlOpVlgGuAkyid/8sBBwJXUi4sh0l6se0/96m4PZMLy9wj6SPAa4HDG0MRhiZgp09uOCVAzSUq0xJNBc62vUPtR/lv4GDb10s6mdJ/sKHtmfWYgf8C5cIy90iaz/ZDwxis0yc3nJJmPvf8GvgSsJKktWw/BNwB7FjHqDwEbNkJTjDYqdINsyiJDvdQ0ukB/kJZJmMtypie/TvBCYbmvDxjwxqcAGz/0/bbKSn2X6nDM74JPEqZwujuTnBSWfAzBkBqUHOZpH2At9t+tcpkp4cC/wfsafu+Ya0dpLM/5pZh75MbJglQc1kdtX8kZTLTB4ALm3d2w3wBzoUl5pZh75MbFglQXVJrUg/Z/lp9ni8PubDE3DPMfXLDIgGqB3IBfqJcWGJuyWdosCVARV/kwhIRTycBKiIiWilp5hER0UoJUBER0UoJUBER0UoJUBER0UoJUBE9JmkRSV1f20rSVnX2/IgxKQEqovcWAeY4QKl4Nt/VrYAEqBizkmYe0WOSTgO2pCza+AtgdWBRYF7gINtnSVoeOLe+vh4l2OwMvBO4HbgXuMr2FyWtSJnRewJl3sf3UlYjPoeyBMzfgW1s/7FHf2LEXDFPvwsQMYQOoCxxv6akeYDn275f0hLAFZLOrvutBLzL9h6SplDmL1yL8r29Griq7nc88H7bN0t6FWVxzI3q+5xj+4xe/nERc0sCVER/CThM0mspS0dMBJaqr/3Z9hX18QbAWbb/CSDpR/X3QsCrge+V9SGBsvZWxJiXABXRX++kNM2tbfthSbcC89fX/tHYTyMPrMYBf7O9ZtdKGNEnSZKI6L0HgBfUxy8E7qnBaUPgxU9xzP8Am0uav9aa3gxg+37glroycSehYo1R/p2IMScBKqLHbN8HXCbp98CawBRJ0yi1qRuf4phfA2cDvwV+AEyjJD9Qj9tV0m+B6ygJGACnAftL+k1NpIgYU5LFFzFGSFrI9oOSng9cAuxm++p+lyuiW9IHFTF2HF8H3s4PTE1wikGXGlRERLRS+qAiIqKVEqAiIqKVEqAiIqKVEqAiIqKVEqAiIqKVEqAiIqKV/j+IMP4mD18gNAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot class distribution\n",
    "print(\"Ploting class distribution ..\")\n",
    "pltdist= sns.countplot(nice_y)\n",
    "pltdist.set_xticklabels(pltdist.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Scaling dataset\")\n",
    "# scaler = StandardScaler()\n",
    "# scaler = RobustScaler()\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, index=X.index, columns=X.columns) # transform back to df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Starting of experiment for DNN only\n",
    "\n",
    "Parameters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Name of experiment\n",
    "# DNN\n",
    "prefix = 'Phase1_dnn_evs'\n",
    "dnn = True # needed for special reporting features\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Dropout, LSTM, SimpleRNN\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "paramgrid = {\n",
    "    \"optimizer\": [\"adam\", \"adagrad\", \"sgd\"],\n",
    "    \"learning_r\": [0.01, 0.0001 , 0.003, 0.001],\n",
    "    \"patience\" : [4],\n",
    "    \"batch_size\": [512], # use yellowbrick\n",
    "    \"epochs\": [300],\n",
    "    \"kernel_init\": ['he_uniform', 'he_normal'],\n",
    "    \"layer_1\": [0, 50, 100],\n",
    "    \"layer_2\": [0,  50, 100],\n",
    "    \"layer_3\": [0,  50, 100],\n",
    "    \"layer_0\": [0, 200, 100, 50],\n",
    "    \"drop\": [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    \"loss\": [\"categorical_crossentropy\"],\n",
    "    \"activation_1\": ['relu', 'elu', 'selu'],\n",
    "    \"out_activation\":[\"sigmoid\"]\n",
    "}\n",
    "\n",
    "y_oh = pd.get_dummies(y, prefix='target')\n",
    "\n",
    "# Reverse one hot encoding\n",
    "def reverse_oh(y_oh):\n",
    "    decode = []\n",
    "    for r in y_oh:\n",
    "        # print(r)\n",
    "        result = np.where(r == 1.)[0]\n",
    "        # print(result)\n",
    "        #check if network asigned more than one or non labels\n",
    "        if len(result) > 1 or len(result) == 0:\n",
    "            if len(result) > 1:\n",
    "                result = np.array([result[0]])  # select first class\n",
    "            elif len(result) == 0:\n",
    "                result = np.array([0])\n",
    "\n",
    "        decode.append(result[0])\n",
    "    return decode\n",
    "\n",
    "\n",
    "def dnn_aspide(optimizer='adam', #adam, adagrad, sgd\n",
    "               learning_r = 0.01,\n",
    "              patience=5,\n",
    "              batch_size=32,\n",
    "              epochs=1000,\n",
    "              kernel_init='he_uniform',\n",
    "              layer_1 = 20,\n",
    "              layer_2 = 40,\n",
    "              layer_3 = 40,\n",
    "              layer_0 = 100,\n",
    "              drop = 0.1,\n",
    "              loss='categorical_crossentropy',\n",
    "              activation_1 = 'relu', # elu, selu\n",
    "              out_activation='sigmoid'):\n",
    "    y_oh = pd.get_dummies(y, prefix='target')\n",
    "#     print(np.asarray(X).shape[1], len(y_oh.nunique()))\n",
    "#     print(len(y_oh.nunique()))\n",
    "    n_inputs, n_outputs = X.shape[1], 5 # if unique is lower than acutal len(y_oh.nunique()) might not work\n",
    "    model = Sequential()\n",
    "    # model.add(Conv1D(filters=32, kernel_size=2,activation=activation_1, input_shape=n_inputs, kernel_initializer=kernel_init))\n",
    "    model.add(Dense(layer_0, input_dim=n_inputs, kernel_initializer=kernel_init, activation=activation_1))\n",
    "    if drop:\n",
    "        model.add(Dropout(drop))\n",
    "    if layer_1:\n",
    "        model.add(Dense(layer_1, input_dim=n_inputs, kernel_initializer=kernel_init, activation=activation_1))\n",
    "        if drop:\n",
    "            model.add(Dropout(drop))\n",
    "    if layer_2:\n",
    "        model.add(Dense(layer_2, input_dim=n_inputs, kernel_initializer=kernel_init, activation=activation_1))\n",
    "        if drop:\n",
    "            model.add(Dropout(drop))\n",
    "    if layer_3:\n",
    "        model.add(Dense(layer_2, input_dim=n_inputs, kernel_initializer=kernel_init, activation=activation_1))\n",
    "        if drop:\n",
    "            model.add(Dropout(drop))\n",
    "    model.add(Dense(n_outputs, activation=out_activation))\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_r)\n",
    "    if optimizer == 'adagrad':\n",
    "        opt = Adagrad(learning_rate=learning_r)\n",
    "    if optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_r)\n",
    "    else:\n",
    "        opt = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer = opt, loss=loss, metrics=['accuracy', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "    early_stopping = EarlyStopping(monitor=\"loss\", patience = patience)# early stop patience\n",
    "    history = model.fit(np.asarray(X), np.asarray(y_oh),\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              callbacks = [early_stopping],\n",
    "              verbose=0) #verbose set to 1 will show the training process\n",
    "    # df_history = pd.DataFrame(h.history)\n",
    "    # df_history\n",
    "    return model\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "def dnn_serrano(optimizer='adam', #adam, adagrad, sgd\n",
    "               learning_r = 0.01,\n",
    "              patience=5,\n",
    "              batch_size=32,\n",
    "              epochs=1000,\n",
    "              kernel_init='he_uniform',\n",
    "              layer_1 = 20,\n",
    "              layer_2 = 40,\n",
    "              layer_3 = 40,\n",
    "              layer_0 = 100,\n",
    "              drop = 0.1,\n",
    "              loss='categorical_crossentropy',\n",
    "              activation_1 = 'relu', # elu, selu\n",
    "              out_activation='sigmoid'):\n",
    "    y_oh = pd.get_dummies(y, prefix='target')\n",
    "    n_inputs, n_outputs = X.shape[1], len(y_oh.nunique())\n",
    "    x_in = Input(shape=n_inputs)\n",
    "    if layer_0:\n",
    "        x=Dense(layer_0, input_dim=n_inputs, kernel_initializer=kernel_init, activation=activation_1)(x_in)\n",
    "        x=Dropout(drop)(x)\n",
    "    if layer_1:\n",
    "        x=Dense(layer_1, input_dim=n_inputs, kernel_initializer=kernel_init, activation=activation_1)(x)\n",
    "        x=Dropout(drop)(x)\n",
    "    if layer_2:\n",
    "        x=Dense(layer_2, input_dim=n_inputs, kernel_initializer=kernel_init, activation=activation_1)(x)\n",
    "        x=Dropout(drop)(x)\n",
    "    if layer_3:\n",
    "        x=Dense(layer_3, input_dim=n_inputs, kernel_initializer=kernel_init, activation=activation_1)(x)\n",
    "        x=Dropout(drop)(x)\n",
    "    x_out = Dense(n_outputs, activation=out_activation)(x)\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_r)\n",
    "    if optimizer == 'adagrad':\n",
    "        opt = Adagrad(learning_rate=learning_r)\n",
    "    if optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_r)\n",
    "    else:\n",
    "        opt = Adam(learning_rate=0.01)\n",
    "    model = Model(inputs=x_in, outputs=x_out)\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=['accuracy', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "    early_stopping = EarlyStopping(monitor=\"loss\", patience = patience)# early stop patience\n",
    "    history = model.fit(np.asarray(X), np.asarray(y_oh),\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        callbacks = [early_stopping],\n",
    "                        verbose=0) #verbose set to 1 will show the training process\n",
    "\n",
    "    return model\n",
    "\n",
    "# model_v = dnn_aspide()\n",
    "# model_v.summary()\n",
    "model = KerasClassifier(build_fn=dnn_serrano, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gabriel/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/Users/Gabriel/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "#Example of HPO methods https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms/blob/master/HPO_Classification.ipynb\n",
    "# scorer = make_scorer(accuracy_score, )\n",
    "scorer = make_scorer(jaccard_score, average=\"micro\") # TODO check average\n",
    "# scorer = 'accuracy'\n",
    "n_splits = 2 # default 4\n",
    "\n",
    "# cv_type = StratifiedKFold(n_splits=n_splits)\n",
    "cv_type = None\n",
    "nj = 1 # Number of jobs set to 1 for DNN\n",
    "\n",
    "cv = EvolutionaryAlgorithmSearchCV(estimator=model,\n",
    "                                   params=paramgrid,\n",
    "                                   scoring=scorer,\n",
    "                                   cv=cv_type, # StratifiedKFold not supported for multilabel-indicator (oh encoding)\n",
    "                                   verbose=4,\n",
    "                                   population_size=20, # 40\n",
    "                                   gene_mutation_prob=0.20,\n",
    "                                   gene_crossover_prob=0.5,\n",
    "                                   tournament_size=4,\n",
    "                                   generations_number=10, #10\n",
    "                                   n_jobs=nj) # for dnn n_jobs must be set to 1 rest is 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] and maxint [2, 3, 0, 0, 0, 1, 2, 2, 2, 3, 4, 0, 2, 0] detected\n",
      "--- Evolve in 38880 possible combinations ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 22:13:22.401560: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-03 22:13:22.484447: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/evolutionary_search/cv.py:419\u001B[0m, in \u001B[0;36mEvolutionaryAlgorithmSearchCV.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m possible_params \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpossible_params:\n\u001B[1;32m    418\u001B[0m     _check_param_grid(possible_params)\n\u001B[0;32m--> 419\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpossible_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrefit:\n\u001B[1;32m    421\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_estimator_ \u001B[38;5;241m=\u001B[39m clone(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimator)\n",
      "File \u001B[0;32m~/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/evolutionary_search/cv.py:539\u001B[0m, in \u001B[0;36mEvolutionaryAlgorithmSearchCV._fit\u001B[0;34m(self, X, y, parameter_dict)\u001B[0m\n\u001B[1;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n\u001B[1;32m    533\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    534\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--- Evolve in \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m possible combinations ---\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    535\u001B[0m             np\u001B[38;5;241m.\u001B[39mprod(np\u001B[38;5;241m.\u001B[39marray(maxints) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    536\u001B[0m         )\n\u001B[1;32m    537\u001B[0m     )\n\u001B[0;32m--> 539\u001B[0m pop, logbook \u001B[38;5;241m=\u001B[39m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meaSimple\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    540\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    541\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoolbox\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    542\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcxpb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmutpb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[43mngen\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerations_number\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstats\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhalloffame\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhof\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    547\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    548\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[38;5;66;03m# Save History\u001B[39;00m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mall_history_\u001B[38;5;241m.\u001B[39mappend(hist)\n",
      "File \u001B[0;32m~/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/deap/algorithms.py:151\u001B[0m, in \u001B[0;36meaSimple\u001B[0;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001B[0m\n\u001B[1;32m    149\u001B[0m invalid_ind \u001B[38;5;241m=\u001B[39m [ind \u001B[38;5;28;01mfor\u001B[39;00m ind \u001B[38;5;129;01min\u001B[39;00m population \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ind\u001B[38;5;241m.\u001B[39mfitness\u001B[38;5;241m.\u001B[39mvalid]\n\u001B[1;32m    150\u001B[0m fitnesses \u001B[38;5;241m=\u001B[39m toolbox\u001B[38;5;241m.\u001B[39mmap(toolbox\u001B[38;5;241m.\u001B[39mevaluate, invalid_ind)\n\u001B[0;32m--> 151\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ind, fit \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(invalid_ind, fitnesses):\n\u001B[1;32m    152\u001B[0m     ind\u001B[38;5;241m.\u001B[39mfitness\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;241m=\u001B[39m fit\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m halloffame \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/evolutionary_search/cv.py:119\u001B[0m, in \u001B[0;36m_evalFunction\u001B[0;34m(individual, name_values, X, y, scorer, cv, iid, fit_params, verbose, error_score, score_cache)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m cv\u001B[38;5;241m.\u001B[39msplit(X, y):\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[1;32m    117\u001B[0m         \u001B[38;5;28mlen\u001B[39m(train) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(test) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    118\u001B[0m     ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining and/or testing not long enough for evaluation.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 119\u001B[0m     _score \u001B[38;5;241m=\u001B[39m \u001B[43m_fit_and_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindividual\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    121\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    123\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscorer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    124\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    125\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    126\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    132\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m iid:\n\u001B[1;32m    133\u001B[0m         score \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m _score \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(test)\n",
      "File \u001B[0;32m~/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:702\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    699\u001B[0m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_error\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    701\u001B[0m fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n\u001B[0;32m--> 702\u001B[0m test_scores \u001B[38;5;241m=\u001B[39m \u001B[43m_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    703\u001B[0m score_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time \u001B[38;5;241m-\u001B[39m fit_time\n\u001B[1;32m    704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_train_score:\n",
      "File \u001B[0;32m~/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:761\u001B[0m, in \u001B[0;36m_score\u001B[0;34m(estimator, X_test, y_test, scorer, error_score)\u001B[0m\n\u001B[1;32m    759\u001B[0m         scores \u001B[38;5;241m=\u001B[39m scorer(estimator, X_test)\n\u001B[1;32m    760\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 761\u001B[0m         scores \u001B[38;5;241m=\u001B[39m \u001B[43mscorer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    762\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    763\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m error_score \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py:216\u001B[0m, in \u001B[0;36m_BaseScorer.__call__\u001B[0;34m(self, estimator, X, y_true, sample_weight)\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, estimator, X, y_true, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \n\u001B[1;32m    196\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;124;03m        Score function applied to prediction of estimator on X.\u001B[39;00m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_cached_call\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    220\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py:258\u001B[0m, in \u001B[0;36m_PredictScorer._score\u001B[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001B[0m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_score\u001B[39m(\u001B[38;5;28mself\u001B[39m, method_caller, estimator, X, y_true, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    231\u001B[0m     \u001B[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001B[39;00m\n\u001B[1;32m    232\u001B[0m \n\u001B[1;32m    233\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;124;03m        Score function applied to prediction of estimator on X.\u001B[39;00m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 258\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmethod_caller\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpredict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sign \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_score_func(\n\u001B[1;32m    261\u001B[0m             y_true, y_pred, sample_weight\u001B[38;5;241m=\u001B[39msample_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_kwargs\n\u001B[1;32m    262\u001B[0m         )\n",
      "File \u001B[0;32m~/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py:68\u001B[0m, in \u001B[0;36m_cached_call\u001B[0;34m(cache, estimator, method, *args, **kwargs)\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;124;03m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 68\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cache[method]\n",
      "File \u001B[0;32m~/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241\u001B[0m, in \u001B[0;36mKerasClassifier.predict\u001B[0;34m(self, x, **kwargs)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;124;03m\"\"\"Returns the class predictions for the given test data.\u001B[39;00m\n\u001B[1;32m    227\u001B[0m \n\u001B[1;32m    228\u001B[0m \u001B[38;5;124;03mArguments:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;124;03m        Class predictions.\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    240\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilter_sk_params(Sequential\u001B[38;5;241m.\u001B[39mpredict_classes, kwargs)\n\u001B[0;32m--> 241\u001B[0m classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_classes\u001B[49m(x, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_[classes]\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Functional' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove bool values from dict\n",
    "cv.cv_results_.pop('nan_test_score?')\n",
    "\n",
    "print(\"Saving CV results\")\n",
    "file_name = \"{}_hpo_best_cv.csv\".format(prefix)\n",
    "# with open(os.path.join(model_dir,file_name), 'w') as cvfile:\n",
    "#     json.dump(cv.cv_results_, cvfile)\n",
    "cv_test_scores = pd.DataFrame(cv.cv_results_)\n",
    "cv_test_scores.to_csv(os.path.join(model_dir,file_name), index=False)\n",
    "print(\"{} best params: {}\".format(prefix, cv.best_params_))\n",
    "param_name = \"{}_hpo_best_param.json\".format(prefix)\n",
    "with open(os.path.join(model_dir,param_name), 'w') as cvfile:\n",
    "    json.dump(cv.best_params_, cvfile)\n",
    "print(\"{} best score: {}\".format(prefix, cv.best_score_))\n",
    "print(\"Saving best {} estimator\".format(prefix))\n",
    "model_name = \"{}_hpo_best.joblib\".format(prefix)\n",
    "dump(cv.best_estimator_, os.path.join(model_dir,model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Scoring and reporting for training\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = cv.best_estimator_.predict(X)\n",
    "custom_scoring_reporting(y_pred, y, definitions, prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConfusion matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m cf_matrix \u001B[38;5;241m=\u001B[39m confusion_matrix(y, \u001B[43my_pred\u001B[49m)\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(dpi\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m600\u001B[39m)\n\u001B[1;32m      4\u001B[0m sns_cf \u001B[38;5;241m=\u001B[39m sns\u001B[38;5;241m.\u001B[39mheatmap(cf_matrix, annot\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, yticklabels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlist\u001B[39m(definitions), xticklabels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlist\u001B[39m(definitions))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix\")\n",
    "cf_matrix = confusion_matrix(y, y_pred)\n",
    "plt.figure(dpi=600)\n",
    "sns_cf = sns.heatmap(cf_matrix, annot=True, yticklabels=list(definitions), xticklabels=list(definitions))\n",
    "cf_fig = \"{}_cf.png\".format(prefix)\n",
    "sns_cf.figure.savefig(os.path.join(model_dir, cf_fig), format='pdf',\n",
    "           bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "\n",
    "# DNN history export\n",
    "df_history = pd.DataFrame(cv.best_estimator_.model.history.history)\n",
    "history_name = \"{}_history.csv\".format(prefix)\n",
    "df_history.to_csv(os.path.join(model_dir, history_name), index=False)\n",
    "df_history\n",
    "# Extract Feature importance\n",
    "# feat_importances = pd.Series(cv.best_estimator_.feature_importances_, index=list(data.drop('target', axis=1).columns))\n",
    "# featureimp_name = \"{}_hpo_best_featureimp.csv\".format(prefix)\n",
    "# feat_importances.to_csv(os.path.join(model_dir, featureimp_name), index=True)\n",
    "# # print(feat_importances.head(10))\n",
    "# sorted_feature = feat_importances.sort_values(ascending=True)\n",
    "# # Plot the feature importances of the forest\n",
    "# # plt.figure()\n",
    "# plt.figure(figsize=(10,20), dpi=600)\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.barh(range(X.shape[1]), sorted_feature,\n",
    "#        color=\"r\", align=\"center\", )\n",
    "# # If you want to define your own labels,\n",
    "# # change indices to a list of labels on the following line.\n",
    "# plt.yticks(range(X.shape[1]), sorted_feature.index)\n",
    "# plt.ylim([-1, X.shape[1]])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving topology\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSaving topology\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m topology_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_topology.png\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(prefix)\n\u001B[0;32m----> 4\u001B[0m plot_model(\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbest_estimator_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m, to_file\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(model_dir, topology_name), show_shapes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "# Export DNN topology\n",
    "print(\"Saving topology\")\n",
    "topology_name = \"{}_topology.png\".format(prefix)\n",
    "plot_model(cv.best_estimator_.model, to_file=os.path.join(model_dir, topology_name), show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scoring on holdout or other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Creating the dependent variable class\n",
    "# factor_h = pd.factorize(df_clean['target'])\n",
    "# df_clean.target = factor_h[0]\n",
    "# definitions_h = factor_h[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Splitting dataset into data and ground truth ...\")\n",
    "# X_h = df_clean.drop('target', axis=1)\n",
    "# y_h = df_clean['target']\n",
    "\n",
    "# Scale\n",
    "# X_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X_h = scaler.transform(X_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# y_pred_h = cv.best_estimator_.predict(X_h)\n",
    "#\n",
    "# custom_scoring_reporting(y_pred_h, y_h, definitions, prefix=\"rf_holdout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%% Scoring and reporting for training\n"
    }
   },
   "outputs": [],
   "source": [
    "# y_pred = cv.best_estimator_.predict(X)\n",
    "# custom_scoring_reporting(y_pred, y, definitions, prefix)\n",
    "\n",
    "# jaccard_score(y_h, y_pred_h, average='micro')\n",
    "# y_pred_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}