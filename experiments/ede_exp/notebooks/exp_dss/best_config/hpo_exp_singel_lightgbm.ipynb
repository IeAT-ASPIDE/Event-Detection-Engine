{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LightGBM Experiments Serrano/AUDSOME Phase 1\n",
    "Anomaly Only\n",
    "Gabriel Iuhasz\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer, classification_report, accuracy_score, jaccard_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "import lightgbm as lgm\n",
    "# from sklearn.externals import joblib\n",
    "from joblib import dump, load\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "from subprocess import check_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% utils\n"
    }
   },
   "outputs": [],
   "source": [
    "def custom_scoring_reporting(y_pred,\n",
    "                             y,\n",
    "                             definitions,\n",
    "                             prefix):\n",
    "    \"\"\"\n",
    "    Custom function for handling scoring and reporting\n",
    "    :param y_pred: model predictions\n",
    "    :param y: ground truth\n",
    "    :param definitions: variable class definitions (factorize)\n",
    "    :param prefix: prefix to saved files and images\n",
    "    :return: 0\n",
    "    \"\"\"\n",
    "    print(\"Accuracy score is: {}\".format(accuracy_score(y, y_pred)))\n",
    "    print(\"Ballanced accuracy score is: {}\".format(balanced_accuracy_score(y, y_pred)))\n",
    "    print(\"Jaccard score (micro): {}\".format(jaccard_score(y, y_pred, average='micro')))\n",
    "    print(\"Jaccard score (macro): {}\".format(jaccard_score(y, y_pred, average='macro')))\n",
    "    print(\"Jaccard score (weighted): {}\".format(jaccard_score(y, y_pred, average='weighted')))\n",
    "\n",
    "\n",
    "    print(\"Full classification report\")\n",
    "    print(classification_report(y, y_pred, digits=4, target_names=definitions))\n",
    "    report = classification_report(y, y_pred, digits=4, output_dict=True)\n",
    "    df_classification_report = pd.DataFrame(report).transpose()\n",
    "    classification_rep_name = \"{}_classification_rep_best.csv\".format(prefix)\n",
    "    df_classification_report.to_csv(os.path.join(model_dir,classification_rep_name), index=False)\n",
    "\n",
    "\n",
    "    print(\"Imbalanced Classification report\")\n",
    "    print(classification_report_imbalanced(y, y_pred, digits=4, target_names=definitions))\n",
    "    imb_report = classification_report_imbalanced(y, y_pred, digits=4, target_names=definitions, output_dict=True)\n",
    "    df_imb_classification_report = pd.DataFrame(imb_report).transpose()\n",
    "    classification_imb_rep_name = \"{}_imb_classification_rep_best.csv\".format(prefix)\n",
    "    df_imb_classification_report.to_csv(os.path.join(model_dir,classification_imb_rep_name), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common preprocessing for all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking files in data location ...\n",
      "data\n",
      "df_anomaly.csv\n",
      "df_audsome.csv\n",
      "df_clean_ausdome_single.csv\n",
      "df_clean_single.csv\n",
      "models\n",
      "processed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking files in data location ...\")\n",
    "train_dir = '/Users/Gabriel/Dropbox/Research/ASPIDE/Datasets/ECI Chaos/Distributed Phase 1/finalized/single_node/training'\n",
    "# train_dir = '/home/gabriel/Research/Aspide/workspace/data_phase'\n",
    "# train_dir = '/home/gabriel/research/dipet/serrano/data'\n",
    "print(check_output([\"ls\", train_dir]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting paths and datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting paths and datasets\")\n",
    "# Checking if directory exists for data, modells and processed\n",
    "\n",
    "data_dir = os.path.join(train_dir,'data')\n",
    "model_dir = os.path.join(train_dir,'models')\n",
    "processed_dir = os.path.join(train_dir,'processed')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "# if not os.path.exists(processed_dir):\n",
    "#     os.makedirs(processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_anomaly = pd.read_csv(os.path.join(train_dir,\"df_anomaly.csv\"))\n",
    "df_audsome = pd.read_csv(os.path.join(train_dir,\"df_audsome.csv\"))\n",
    "df_clean = pd.read_csv(os.path.join(train_dir,\"df_clean_single.csv\"))\n",
    "df_clean_audsome = pd.read_csv(os.path.join(train_dir,\"df_clean_ausdome_single.csv\"))\n",
    "\n",
    "# Set index as time\n",
    "df_anomaly.set_index('time', inplace=True)\n",
    "df_audsome.set_index('time', inplace=True)\n",
    "df_clean.set_index('time', inplace=True)\n",
    "df_clean_audsome.set_index('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%% Choose dataset to run experiments on\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset chosen ...\n"
     ]
    },
    {
     "data": {
      "text/plain": "(5400, 90)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dataset chosen ...\")\n",
    "data = df_anomaly\n",
    "\n",
    "# Nice print\n",
    "nice_y = data['target']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment for removing dummy TODO CHECK if adding back dummy\n",
    "# data.loc[data.target == \"dummy\", 'target'] = \"0\"\n",
    "\n",
    "#Creating the dependent variable class\n",
    "factor = pd.factorize(data['target'])\n",
    "data.target = factor[0]\n",
    "definitions = factor[1]\n",
    "# print(data.target.head())\n",
    "# print(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into training and ground truth ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting dataset into training and ground truth ...\")\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ploting class distribution ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gabriel/anaconda3/envs/p3envmlv3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot class distribution\n",
    "print(\"Ploting class distribution ..\")\n",
    "pltdist= sns.countplot(nice_y)\n",
    "pltdist.set_xticklabels(pltdist.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Scaling dataset\")\n",
    "# scaler = StandardScaler()\n",
    "# scaler = RobustScaler()\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, index=X.index, columns=X.columns) # transform back to df\n",
    "# Fix for lighgbm\n",
    "import re\n",
    "X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Starting of experiment for LightGBM only\n",
    "\n",
    "Parameters:\n",
    "\n",
    "boosting_type (str, optional (default='gbdt')) – ‘gbdt’, traditional Gradient Boosting Decision Tree. ‘dart’, Dropouts meet Multiple Additive Regression Trees. ‘goss’, Gradient-based One-Side Sampling. ‘rf’, Random Forest.\n",
    "\n",
    "num_leaves (int, optional (default=31)) – Maximum tree leaves for base learners.\n",
    "\n",
    "max_depth (int, optional (default=-1)) – Maximum tree depth for base learners, <=0 means no limit.\n",
    "\n",
    "learning_rate (float, optional (default=0.1)) – Boosting learning rate. You can use callbacks parameter of fit method to shrink/adapt learning rate in training using reset_parameter callback. Note, that this will ignore the learning_rate argument in training.\n",
    "\n",
    "n_estimators (int, optional (default=100)) – Number of boosted trees to fit.\n",
    "\n",
    "subsample_for_bin (int, optional (default=200000)) – Number of samples for constructing bins.\n",
    "\n",
    "objective (str, callable or None, optional (default=None)) – Specify the learning task and the corresponding learning objective or a custom objective function to be used (see note below). Default: ‘regression’ for LGBMRegressor, ‘binary’ or ‘multiclass’ for LGBMClassifier, ‘lambdarank’ for LGBMRanker.\n",
    "\n",
    "class_weight (dict, 'balanced' or None, optional (default=None)) – Weights associated with classes in the form {class_label: weight}. Use this parameter only for multi-class classification task; for binary classification task you may use is_unbalance or scale_pos_weight parameters. Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities. You may want to consider performing probability calibration (https://scikit-learn.org/stable/modules/calibration.html) of your model. The ‘balanced’ mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)). If None, all classes are supposed to have weight one. Note, that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.\n",
    "\n",
    "min_split_gain (float, optional (default=0.)) – Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "\n",
    "min_child_weight (float, optional (default=1e-3)) – Minimum sum of instance weight (hessian) needed in a child (leaf).\n",
    "\n",
    "min_child_samples (int, optional (default=20)) – Minimum number of data needed in a child (leaf).\n",
    "\n",
    "subsample (float, optional (default=1.)) – Subsample ratio of the training instance.\n",
    "\n",
    "subsample_freq (int, optional (default=0)) – Frequency of subsample, <=0 means no enable.\n",
    "\n",
    "colsample_bytree (float, optional (default=1.)) – Subsample ratio of columns when constructing each tree.\n",
    "\n",
    "reg_alpha (float, optional (default=0.)) – L1 regularization term on weights.\n",
    "\n",
    "reg_lambda (float, optional (default=0.)) – L2 regularization term on weights.\n",
    "\n",
    "random_state (int, RandomState object or None, optional (default=None)) – Random number seed. If int, this number is used to seed the C++ code. If RandomState object (numpy), a random integer is picked based on its state to seed the C++ code. If None, default seeds in C++ code are used.\n",
    "\n",
    "n_jobs (int, optional (default=-1)) – Number of parallel threads to use for training (can be changed at prediction time).\n",
    "\n",
    "importance_type (str, optional (default='split')) – The type of feature importance to be filled into feature_importances_. If ‘split’, result contains numbers of times the feature is used in a model. If ‘gain’, result contains total gains of splits which use the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type', 'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight', 'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample', 'subsample_for_bin', 'subsample_freq'])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name of experiment\n",
    "# XGBoost\n",
    "prefix = 'Phase1_lightgbm_evs_as'\n",
    "paramgrid = {\n",
    "    'n_estimators': [10, 50, 100, 200, 300, 500, 1000],\n",
    "    'max_depth': [-1, 3, 4, 6, 25, 50],\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'subsample': [0.2, 0.5, 1],\n",
    "    'min_child_weight':[1, 2, 5, 6],\n",
    "    'boosting_type':[\"gbdt\", \"dart\", \"goss\"],\n",
    "    'seed': [42],\n",
    "    'objective': ['multiclass'],  # error evaluation for multiclass training\n",
    "    # 'num_class': [len(definitions)],\n",
    "}\n",
    "model = lgm.sklearn.LGBMClassifier()\n",
    "# model = xgb.XGBClassifier()\n",
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Example of HPO methods https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms/blob/master/HPO_Classification.ipynb\n",
    "# scorer = make_scorer(accuracy_score, )\n",
    "scorer = make_scorer(jaccard_score, average=\"micro\") # TODO check average\n",
    "# scorer = 'accuracy'\n",
    "n_splits = 4 # default 4\n",
    "\n",
    "cv_type = StratifiedKFold(n_splits=n_splits)\n",
    "nj = 1 # Number of jobs\n",
    "from joblib import parallel_backend\n",
    "with parallel_backend('multiprocessing'):\n",
    "    cv = EvolutionaryAlgorithmSearchCV(estimator=model,\n",
    "                                       params=paramgrid,\n",
    "                                       scoring=scorer,\n",
    "                                       cv=cv_type, # StratifiedKFold not supported for multilabel-indicator (oh encoding)\n",
    "                                       verbose=4,\n",
    "                                       population_size=40, # 40\n",
    "                                       gene_mutation_prob=0.20,\n",
    "                                       gene_crossover_prob=0.5,\n",
    "                                       tournament_size=4,\n",
    "                                       generations_number=30, #10\n",
    "                                       n_jobs=nj) # for dnn n_jobs must be set to 1 rest is 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1, 1, 2, 2, 1, 1, 1, 1] and maxint [6, 5, 5, 2, 3, 2, 0, 0] detected\n",
      "--- Evolve in 9072 possible combinations ---\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, max_depth=50, min_child_weight=5, n_estimators=50, objective=multiclass, seed=42, subsample=0.2;, score=0.987 total time=   2.7s\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, max_depth=50, min_child_weight=5, n_estimators=50, objective=multiclass, seed=42, subsample=0.2;, score=0.988 total time=   2.7s\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, max_depth=50, min_child_weight=5, n_estimators=50, objective=multiclass, seed=42, subsample=0.2;, score=0.972 total time=   2.3s\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, max_depth=50, min_child_weight=5, n_estimators=50, objective=multiclass, seed=42, subsample=0.2;, score=0.996 total time=   2.5s\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=1000, objective=multiclass, seed=42, subsample=0.5;, score=0.944 total time=   9.3s\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=1000, objective=multiclass, seed=42, subsample=0.5;, score=0.985 total time=  10.1s\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=1000, objective=multiclass, seed=42, subsample=0.5;, score=0.871 total time=   9.7s\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=1000, objective=multiclass, seed=42, subsample=0.5;, score=0.964 total time=  11.6s\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, max_depth=3, min_child_weight=2, n_estimators=200, objective=multiclass, seed=42, subsample=1;, score=0.941 total time=   2.1s\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, max_depth=3, min_child_weight=2, n_estimators=200, objective=multiclass, seed=42, subsample=1;, score=0.984 total time=   2.1s\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, max_depth=3, min_child_weight=2, n_estimators=200, objective=multiclass, seed=42, subsample=1;, score=0.860 total time=   1.9s\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, max_depth=3, min_child_weight=2, n_estimators=200, objective=multiclass, seed=42, subsample=1;, score=0.982 total time=   2.3s\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=300, objective=multiclass, seed=42, subsample=0.2;, score=0.945 total time=   3.2s\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=300, objective=multiclass, seed=42, subsample=0.2;, score=0.965 total time=   2.8s\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=300, objective=multiclass, seed=42, subsample=0.2;, score=0.816 total time=   2.5s\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=300, objective=multiclass, seed=42, subsample=0.2;, score=0.972 total time=   2.7s\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, max_depth=25, min_child_weight=1, n_estimators=100, objective=multiclass, seed=42, subsample=0.2;, score=0.962 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove bool values from dict\n",
    "cv.cv_results_.pop('nan_test_score?')\n",
    "\n",
    "print(\"Saving CV results\")\n",
    "file_name = \"{}_hpo_best_cv.csv\".format(prefix)\n",
    "# with open(os.path.join(model_dir,file_name), 'w') as cvfile:\n",
    "#     json.dump(cv.cv_results_, cvfile)\n",
    "cv_test_scores = pd.DataFrame(cv.cv_results_)\n",
    "cv_test_scores.to_csv(os.path.join(model_dir,file_name), index=False)\n",
    "print(\"{} best params: {}\".format(prefix, cv.best_params_))\n",
    "param_name = \"{}_hpo_best_param.json\".format(prefix)\n",
    "with open(os.path.join(model_dir,param_name), 'w') as cvfile:\n",
    "    json.dump(cv.best_params_, cvfile)\n",
    "print(\"{} best score: {}\".format(prefix, cv.best_score_))\n",
    "print(\"Saving best {} estimator\".format(prefix))\n",
    "model_name = \"{}_hpo_best.joblib\".format(prefix)\n",
    "dump(cv.best_estimator_, os.path.join(model_dir,model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Scoring and reporting for training\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = cv.best_estimator_.predict(X)\n",
    "custom_scoring_reporting(y_pred, y, definitions, prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Confusion matrix\")\n",
    "cf_matrix = confusion_matrix(y, y_pred)\n",
    "plt.figure(dpi=600)\n",
    "sns_cf = sns.heatmap(cf_matrix, annot=True, yticklabels=list(definitions), xticklabels=list(definitions))\n",
    "cf_fig = \"{}_cf.png\".format(prefix)\n",
    "sns_cf.figure.savefig(os.path.join(model_dir, cf_fig), format='pdf',\n",
    "           bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "# Extract Feature importance\n",
    "feat_importances = pd.Series(cv.best_estimator_.feature_importances_, index=list(data.drop('target', axis=1).columns))\n",
    "featureimp_name = \"{}_hpo_best_featureimp.csv\".format(prefix)\n",
    "feat_importances.to_csv(os.path.join(model_dir, featureimp_name), index=True)\n",
    "# print(feat_importances.head(10))\n",
    "sorted_feature = feat_importances.sort_values(ascending=True)\n",
    "# Plot the feature importances of the forest\n",
    "# plt.figure()\n",
    "plt.figure(figsize=(10,20), dpi=600)\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(X.shape[1]), sorted_feature,\n",
    "       color=\"r\", align=\"center\", )\n",
    "# If you want to define your own labels,\n",
    "# change indices to a list of labels on the following line.\n",
    "plt.yticks(range(X.shape[1]), sorted_feature.index)\n",
    "plt.ylim([-1, X.shape[1]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scoring on holdout or other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Creating the dependent variable class\n",
    "# factor_h = pd.factorize(df_clean['target'])\n",
    "# df_clean.target = factor_h[0]\n",
    "# definitions_h = factor_h[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Splitting dataset into data and ground truth ...\")\n",
    "# X_h = df_clean.drop('target', axis=1)\n",
    "# y_h = df_clean['target']\n",
    "\n",
    "# Scale\n",
    "# X_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X_h = scaler.transform(X_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# y_pred_h = cv.best_estimator_.predict(X_h)\n",
    "#\n",
    "# custom_scoring_reporting(y_pred_h, y_h, definitions, prefix=\"rf_holdout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%% Scoring and reporting for training\n"
    }
   },
   "outputs": [],
   "source": [
    "# y_pred = cv.best_estimator_.predict(X)\n",
    "# custom_scoring_reporting(y_pred, y, definitions, prefix)\n",
    "\n",
    "# jaccard_score(y_h, y_pred_h, average='micro')\n",
    "# y_pred_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}